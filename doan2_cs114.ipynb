{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat('it001',`assignment_id`)</th>\n",
       "      <th>concat('it001',`problem_id`)</th>\n",
       "      <th>concat('it001', username)</th>\n",
       "      <th>is_final</th>\n",
       "      <th>status</th>\n",
       "      <th>pre_score</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>concat('it001',`language_id`)</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90ce27571176d87961b565d5ef4b3de33ede04ac</td>\n",
       "      <td>789454427dd4097a14749e3dde63346b7a8d3811</td>\n",
       "      <td>ed9eaeb6a707f50154024b24d7efcb874a9795dd</td>\n",
       "      <td>0</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>10-09 08:02:04</td>\n",
       "      <td>10-09 08:06:58</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90ce27571176d87961b565d5ef4b3de33ede04ac</td>\n",
       "      <td>789454427dd4097a14749e3dde63346b7a8d3811</td>\n",
       "      <td>ed9eaeb6a707f50154024b24d7efcb874a9795dd</td>\n",
       "      <td>0</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>10-09 08:04:41</td>\n",
       "      <td>10-09 08:04:51</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90ce27571176d87961b565d5ef4b3de33ede04ac</td>\n",
       "      <td>789454427dd4097a14749e3dde63346b7a8d3811</td>\n",
       "      <td>ed9eaeb6a707f50154024b24d7efcb874a9795dd</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>10-09 08:06:49</td>\n",
       "      <td>10-09 08:06:58</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90ce27571176d87961b565d5ef4b3de33ede04ac</td>\n",
       "      <td>bf96fbdc5f499538c3e2bfbec5779c8a14b0a9ff</td>\n",
       "      <td>ed9eaeb6a707f50154024b24d7efcb874a9795dd</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>10-09 08:47:52</td>\n",
       "      <td>10-09 08:48:01</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90ce27571176d87961b565d5ef4b3de33ede04ac</td>\n",
       "      <td>7a6e5ca470ff47c3b5048f240c4738de71010c78</td>\n",
       "      <td>ed9eaeb6a707f50154024b24d7efcb874a9795dd</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>10-09 09:19:35</td>\n",
       "      <td>10-09 09:19:45</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295193</th>\n",
       "      <td>613aea04c978f5e72fffc8bcff1f7b695a63f7b1</td>\n",
       "      <td>388516cbf597351226be1bdbe5ef30b9dcef570f</td>\n",
       "      <td>232cce96362898f08e9150ba244adaf2d6583ab2</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>01-15 16:03:43</td>\n",
       "      <td>01-15 16:03:53</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295194</th>\n",
       "      <td>613aea04c978f5e72fffc8bcff1f7b695a63f7b1</td>\n",
       "      <td>d2b96124ccb8e27b4b8dacdb935e729cb1ba546b</td>\n",
       "      <td>232cce96362898f08e9150ba244adaf2d6583ab2</td>\n",
       "      <td>0</td>\n",
       "      <td>Compilation Error</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>01-15 16:04:07</td>\n",
       "      <td>01-15 16:05:08</td>\n",
       "      <td>{\"times\":[],\"mems\":[],\"verdicts\":{\"\\n\\nIn func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295195</th>\n",
       "      <td>613aea04c978f5e72fffc8bcff1f7b695a63f7b1</td>\n",
       "      <td>d2b96124ccb8e27b4b8dacdb935e729cb1ba546b</td>\n",
       "      <td>232cce96362898f08e9150ba244adaf2d6583ab2</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>01-15 16:04:58</td>\n",
       "      <td>01-15 16:05:08</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295196</th>\n",
       "      <td>613aea04c978f5e72fffc8bcff1f7b695a63f7b1</td>\n",
       "      <td>8c0f8dd4ff55e1609f733e043ac5e88b1dde6e7c</td>\n",
       "      <td>232cce96362898f08e9150ba244adaf2d6583ab2</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>01-15 16:05:13</td>\n",
       "      <td>01-15 16:05:22</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":[0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295197</th>\n",
       "      <td>613aea04c978f5e72fffc8bcff1f7b695a63f7b1</td>\n",
       "      <td>e1baec9d1d9af44372188067b55edfec747f1342</td>\n",
       "      <td>232cce96362898f08e9150ba244adaf2d6583ab2</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORE</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>it0012</td>\n",
       "      <td>01-15 16:05:40</td>\n",
       "      <td>01-15 16:05:50</td>\n",
       "      <td>{\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295198 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 concat('it001',`assignment_id`)  \\\n",
       "0       90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
       "1       90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
       "2       90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
       "3       90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
       "4       90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
       "...                                          ...   \n",
       "295193  613aea04c978f5e72fffc8bcff1f7b695a63f7b1   \n",
       "295194  613aea04c978f5e72fffc8bcff1f7b695a63f7b1   \n",
       "295195  613aea04c978f5e72fffc8bcff1f7b695a63f7b1   \n",
       "295196  613aea04c978f5e72fffc8bcff1f7b695a63f7b1   \n",
       "295197  613aea04c978f5e72fffc8bcff1f7b695a63f7b1   \n",
       "\n",
       "                    concat('it001',`problem_id`)  \\\n",
       "0       789454427dd4097a14749e3dde63346b7a8d3811   \n",
       "1       789454427dd4097a14749e3dde63346b7a8d3811   \n",
       "2       789454427dd4097a14749e3dde63346b7a8d3811   \n",
       "3       bf96fbdc5f499538c3e2bfbec5779c8a14b0a9ff   \n",
       "4       7a6e5ca470ff47c3b5048f240c4738de71010c78   \n",
       "...                                          ...   \n",
       "295193  388516cbf597351226be1bdbe5ef30b9dcef570f   \n",
       "295194  d2b96124ccb8e27b4b8dacdb935e729cb1ba546b   \n",
       "295195  d2b96124ccb8e27b4b8dacdb935e729cb1ba546b   \n",
       "295196  8c0f8dd4ff55e1609f733e043ac5e88b1dde6e7c   \n",
       "295197  e1baec9d1d9af44372188067b55edfec747f1342   \n",
       "\n",
       "                       concat('it001', username)  is_final             status  \\\n",
       "0       ed9eaeb6a707f50154024b24d7efcb874a9795dd         0              SCORE   \n",
       "1       ed9eaeb6a707f50154024b24d7efcb874a9795dd         0              SCORE   \n",
       "2       ed9eaeb6a707f50154024b24d7efcb874a9795dd         1              SCORE   \n",
       "3       ed9eaeb6a707f50154024b24d7efcb874a9795dd         1              SCORE   \n",
       "4       ed9eaeb6a707f50154024b24d7efcb874a9795dd         1              SCORE   \n",
       "...                                          ...       ...                ...   \n",
       "295193  232cce96362898f08e9150ba244adaf2d6583ab2         1              SCORE   \n",
       "295194  232cce96362898f08e9150ba244adaf2d6583ab2         0  Compilation Error   \n",
       "295195  232cce96362898f08e9150ba244adaf2d6583ab2         1              SCORE   \n",
       "295196  232cce96362898f08e9150ba244adaf2d6583ab2         1              SCORE   \n",
       "295197  232cce96362898f08e9150ba244adaf2d6583ab2         1              SCORE   \n",
       "\n",
       "        pre_score  coefficient concat('it001',`language_id`)      created_at  \\\n",
       "0               0          100                        it0012  10-09 08:02:04   \n",
       "1               0          100                        it0012  10-09 08:04:41   \n",
       "2           10000          100                        it0012  10-09 08:06:49   \n",
       "3           10000          100                        it0012  10-09 08:47:52   \n",
       "4           10000          100                        it0012  10-09 09:19:35   \n",
       "...           ...          ...                           ...             ...   \n",
       "295193      10000          100                        it0012  01-15 16:03:43   \n",
       "295194          0          100                        it0012  01-15 16:04:07   \n",
       "295195      10000          100                        it0012  01-15 16:04:58   \n",
       "295196      10000          100                        it0012  01-15 16:05:13   \n",
       "295197      10000          100                        it0012  01-15 16:05:40   \n",
       "\n",
       "            updated_at                                          judgement  \n",
       "0       10-09 08:06:58  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
       "1       10-09 08:04:51  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
       "2       10-09 08:06:58  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
       "3       10-09 08:48:01  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
       "4       10-09 09:19:45  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
       "...                ...                                                ...  \n",
       "295193  01-15 16:03:53  {\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...  \n",
       "295194  01-15 16:05:08  {\"times\":[],\"mems\":[],\"verdicts\":{\"\\n\\nIn func...  \n",
       "295195  01-15 16:05:08  {\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...  \n",
       "295196  01-15 16:05:22  {\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":[0...  \n",
       "295197  01-15 16:05:50  {\"times\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"mems\":...  \n",
       "\n",
       "[295198 rows x 11 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "data = pd.read_csv('data./annonimized.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_qt = pd.read_csv('./data/qt-public.csv')\n",
    "public_tbtl = pd.read_excel('./data/tbtl-public.ods')\n",
    "public_tbtl.rename(columns={'username':'hash'},inplace=True)\n",
    "public_ck = pd.read_csv('./data/ck-public.csv')\n",
    "public_th = pd.read_csv('./data/th-public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = data.groupby([\"concat('it001', username)\", \"concat('it001',`problem_id`)\"])['pre_score'].mean().reset_index()\n",
    "\n",
    "pivoted_df = mean_scores.pivot_table(\n",
    "    index=\"concat('it001', username)\",\n",
    "    columns=\"concat('it001',`problem_id`)\",\n",
    "    values='pre_score'\n",
    ").reset_index()  \n",
    "\n",
    "pivoted_df = pivoted_df.rename(columns={'index': \"concat('it001', username)\"})\n",
    "\n",
    "problem_cols = [col for col in pivoted_df.columns if col != \"concat('it001', username)\"]\n",
    "pivoted_df.columns = [\"concat('it001', username)\"] + [f'mean_pre_score_{col}' for col in problem_cols]\n",
    "\n",
    "column_means = pivoted_df[pivoted_df.columns[1:]].mean()  \n",
    "mean_pre_score_df = pivoted_df.copy()\n",
    "mean_pre_score_df.iloc[:, 1:] = mean_pre_score_df.iloc[:, 1:].fillna(column_means)\n",
    "mean_pre_score_df.rename(columns={\"concat('it001', username)\":\"username\"},inplace=True)\n",
    "mean_pre_score_cols = mean_pre_score_df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_coef = data.groupby([\"concat('it001', username)\", \"concat('it001',`problem_id`)\"])['coefficient'].mean().reset_index()\n",
    "\n",
    "pivoted_df = mean_coef.pivot_table(\n",
    "    index=\"concat('it001', username)\",\n",
    "    columns=\"concat('it001',`problem_id`)\",\n",
    "    values='coefficient'\n",
    ").reset_index()  \n",
    "pivoted_df = pivoted_df.rename(columns={'index': \"concat('it001', username)\"})\n",
    "\n",
    "problem_cols = [col for col in pivoted_df.columns if col != \"concat('it001', username)\"]\n",
    "pivoted_df.columns = [\"concat('it001', username)\"] + [f'mean_coefficient_{col}' for col in problem_cols]\n",
    "\n",
    "column_means = pivoted_df[pivoted_df.columns[1:]].mean()  \n",
    "mean_coefficient_df = pivoted_df.copy()\n",
    "mean_coefficient_df.iloc[:, 1:] = mean_coefficient_df.iloc[:, 1:].fillna(column_means)\n",
    "mean_coefficient_df.rename(columns={\"concat('it001', username)\":\"username\"},inplace=True)\n",
    "mean_coefficient_cols = mean_coefficient_df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_time_by_problem(df):\n",
    "   \n",
    "    result_df = df.copy()\n",
    "    \n",
    "    year = 2020\n",
    "    \n",
    "    result_df['datetime'] = pd.to_datetime(\n",
    "        str(year) + '-' + result_df['created_at'], \n",
    "        format='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    result_df['solve_time'] = result_df.groupby(\"concat('it001',`problem_id`)\")['datetime'].transform(\n",
    "        lambda x: (x - x.min()).dt.total_seconds() / 60\n",
    "    ).astype(int)\n",
    "    \n",
    "    result_df = result_df.drop('datetime', axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "data = convert_time_by_problem(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    lst = []\n",
    "    for j in x:\n",
    "        try:\n",
    "            lst.append(json.loads(j)['verdicts'])\n",
    "        except:\n",
    "            lst.append({})\n",
    "    return lst\n",
    "judgement_lists = data.groupby(\"concat('it001', username)\")['judgement'].apply(lambda x: process(x)).reset_index()\n",
    "\n",
    "judgement_lists.columns = ['username', 'judgement_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_verdicts(x):\n",
    "    count_wrong = 0\n",
    "    count_time_limit = 0\n",
    "    count_forbidden_phrase = 0\n",
    "    count_error = 0\n",
    "    count_success = 0\n",
    "    for i in x:\n",
    "        try:\n",
    "            if(i == []):\n",
    "                count_success += 1\n",
    "                continue\n",
    "            keys = i.keys()\n",
    "            for key in i.keys():\n",
    "                if ('WRONG' in key):\n",
    "                    count_wrong += i[key]\n",
    "                if ('Time Limit Exceeded' in key):\n",
    "                    count_time_limit += i[key]\n",
    "                if ('error' in key):\n",
    "                    count_error += i[key]\n",
    "                if ('forbidden phrase' in key):\n",
    "                    count_forbidden_phrase += i[key]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return count_wrong,count_time_limit,count_forbidden_phrase,count_error,count_success\n",
    "\n",
    "def process_status(x):\n",
    "    lst = []\n",
    "    for j in x:\n",
    "        try:\n",
    "            lst.append(json.loads(j)['verdicts'])\n",
    "        except:\n",
    "            lst.append({})\n",
    "    return lst\n",
    "def count_status(x):\n",
    "    count_score = 0\n",
    "    count_compilation_error = 0\n",
    "    count_syntax_error = 0\n",
    "    count_pending = 0\n",
    "    for i in x:\n",
    "        if i=='SCORE':\n",
    "            count_score+=1\n",
    "        elif i=='Compilation Error':\n",
    "            count_compilation_error +=1\n",
    "        elif i=='Syntax Error':\n",
    "            count_syntax_error +=1\n",
    "        else:\n",
    "            count_pending +=1\n",
    "    return count_score, count_compilation_error, count_syntax_error, count_pending\n",
    "judgement_lists['all_status'] = data.groupby(\"concat('it001', username)\")['status'].apply(list).reset_index()['status']\n",
    "judgement_lists['count_status'] = judgement_lists['all_status'].apply(lambda x: count_status(x))\n",
    "judgement_lists['count_verdicts'] = judgement_lists['judgement_list'].apply(lambda x:process_verdicts(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgement_lists['mean_coefficient'] = data.groupby(\"concat('it001', username)\")['coefficient'].mean().values\n",
    "judgement_lists['count_submit'] = data.groupby(\"concat('it001', username)\").size().values\n",
    "judgement_lists['mean_pre_score'] = data.groupby(\"concat('it001', username)\")['pre_score'].mean().values\n",
    "judgement_lists['mean_solve_time'] = data.groupby(\"concat('it001', username)\")['solve_time'].mean().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgement_lists['count_wrong'] = judgement_lists['count_verdicts'].apply(lambda x: x[0])\n",
    "judgement_lists['count_time_limit'] = judgement_lists['count_verdicts'].apply(lambda x: x[1])\n",
    "judgement_lists['count_forbidden_phrase'] = judgement_lists['count_verdicts'].apply(lambda x: x[2])\n",
    "judgement_lists['count_error'] = judgement_lists['count_verdicts'].apply(lambda x: x[3])\n",
    "judgement_lists['count_success'] = judgement_lists['count_verdicts'].apply(lambda x: x[4])\n",
    "\n",
    "\n",
    "judgement_lists['count_score'] = judgement_lists['count_status'].apply(lambda x: x[0])\n",
    "judgement_lists['count_compilation_error'] = judgement_lists['count_status'].apply(lambda x: x[1])\n",
    "judgement_lists['count_syntax_error'] = judgement_lists['count_status'].apply(lambda x: x[2])\n",
    "judgement_lists['count_pending'] = judgement_lists['count_status'].apply(lambda x: x[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_score_50 = data[data['pre_score'] <= 5000].groupby(\"concat('it001', username)\").size()\n",
    "pre_score_75 = data[(data['pre_score'] > 5000) & (data['pre_score'] <= 7500)].groupby(\"concat('it001', username)\").size()\n",
    "pre_score_90 = data[(data['pre_score'] > 7500) & (data['pre_score'] <= 9000)].groupby(\"concat('it001', username)\").size()\n",
    "pre_score_100 = data[data['pre_score'] > 9000].groupby(\"concat('it001', username)\").size()\n",
    "\n",
    "all_students = judgement_lists['username']\n",
    "\n",
    "judgement_lists['pre_score_50'] = pre_score_50.reindex(all_students, fill_value=0).values\n",
    "judgement_lists['pre_score_75'] = pre_score_75.reindex(all_students, fill_value=0).values\n",
    "judgement_lists['pre_score_90'] = pre_score_90.reindex(all_students, fill_value=0).values\n",
    "judgement_lists['pre_score_100'] = pre_score_100.reindex(all_students, fill_value=0).values\n",
    "\n",
    "judgement_lists = judgement_lists.merge(mean_pre_score_df,on=\"username\")\n",
    "judgement_lists = judgement_lists.merge(mean_coefficient_df,on=\"username\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_data_ck = judgement_lists.merge(public_ck,left_on=\"username\",right_on='hash').dropna()\n",
    "final_data_th = judgement_lists.merge(public_th,left_on=\"username\",right_on='hash').dropna()\n",
    "final_data_qt = judgement_lists.merge(public_qt,left_on=\"username\",right_on='hash').dropna()\n",
    "final_data_tbtl = judgement_lists.merge(public_tbtl,left_on='username',right_on='hash').dropna()\n",
    "\n",
    "final_data_th['TH'] = final_data_th['TH'].str.replace('\\xa0', '', regex=False).str.strip()\n",
    "\n",
    "final_data_th['TH'] = final_data_th['TH'].replace('', np.nan)\n",
    "final_data_th['TH'] = final_data_th['TH'].astype(float).dropna()\n",
    "final_data_th = final_data_th.dropna()\n",
    "final_data_qt['diemqt'] = final_data_qt['diemqt'].str.replace('\\xa0', '', regex=False).str.strip()\n",
    "\n",
    "final_data_qt['diemqt'] = final_data_qt['diemqt'].replace('', np.nan)\n",
    "final_data_qt['diemqt'] = final_data_qt['diemqt'].astype(float)\n",
    "final_data_qt = final_data_qt.dropna()\n",
    "\n",
    "final_data_ck['CK'] = final_data_ck['CK'].replace('', np.nan)\n",
    "final_data_ck['CK'] = final_data_ck['CK'].astype(float)\n",
    "final_data_ck = final_data_ck.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 0.543624\tvalid_1's rmse: 0.836153\n",
      "Fold 1 RMSE: 0.8362\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's rmse: 0.435773\tvalid_1's rmse: 0.768408\n",
      "Fold 2 RMSE: 0.7684\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's rmse: 0.494673\tvalid_1's rmse: 0.703351\n",
      "Fold 3 RMSE: 0.7034\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's rmse: 0.538441\tvalid_1's rmse: 0.859821\n",
      "Fold 4 RMSE: 0.8598\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.203719\tvalid_1's rmse: 0.861341\n",
      "Fold 5 RMSE: 0.8613\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "feature_cols = ['count_submit', 'count_wrong', 'count_time_limit', \n",
    "                'count_forbidden_phrase', 'count_error', 'count_success',\n",
    "                'mean_coefficient', 'mean_pre_score','count_score','count_compilation_error','count_syntax_error',\n",
    "                'mean_solve_time'\n",
    "                ] + mean_pre_score_cols+ mean_coefficient_cols\n",
    "\n",
    "\n",
    "# target_col = 'diemqt'; X = final_data_qt[feature_cols];y = final_data_qt[target_col];score_df = public_qt\n",
    "# target_col = 'TH'; X = final_data_th[feature_cols];y = final_data_th[target_col];score_df = public_th\n",
    "# target_col = 'CK'; X = final_data_ck[feature_cols];y = final_data_ck[target_col];score_df = public_ck\n",
    "target_col = 'TBTL'; X = final_data_tbtl[feature_cols];y = final_data_tbtl[target_col];score_df = public_tbtl\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',          \n",
    "    'metric': 'rmse',                   \n",
    "    'boosting_type': 'gbdt',            \n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,                   \n",
    "    'verbose': -1                       \n",
    "}\n",
    "\n",
    "models = []\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "    ]    )\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    \n",
    "    fold_rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    fold_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold + 1} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_data = judgement_lists.merge(score_df,left_on=\"username\",right_on='hash',how='left')\n",
    "test_data = all_data[all_data[target_col].isna()]\n",
    "\n",
    "X_test = test_data[feature_cols]  \n",
    "predictions = np.mean([model.predict(X_test, num_iteration=model.best_iteration,predict_disable_shape_check=True) for model in models], axis=0)\n",
    "submit_df =pd.DataFrame({'username':test_data['username'],'score':predictions})\n",
    "submit_df.to_csv('submit.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's rmse: 0.774104\tvalid_1's rmse: 1.69339\n",
      "Fold 1 RMSE: 1.6934\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's rmse: 0.89317\tvalid_1's rmse: 1.66431\n",
      "Fold 2 RMSE: 1.6643\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's rmse: 0.427518\tvalid_1's rmse: 1.63726\n",
      "Fold 3 RMSE: 1.6373\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's rmse: 0.612001\tvalid_1's rmse: 1.6429\n",
      "Fold 4 RMSE: 1.6429\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[461]\ttraining's rmse: 0.195999\tvalid_1's rmse: 1.73153\n",
      "Fold 5 RMSE: 1.7315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "feature_cols = ['count_submit', 'count_wrong', 'count_time_limit',\n",
    "                'count_forbidden_phrase', 'count_error', 'count_success',\n",
    "                'mean_coefficient', 'mean_pre_score', 'count_score', \n",
    "                'count_compilation_error', 'count_syntax_error',\n",
    "                'mean_solve_time'] + mean_pre_score_cols + mean_coefficient_cols\n",
    "\n",
    "# target_col = 'diemqt'; X = final_data_qt[feature_cols]; y = final_data_qt[target_col]; score_df = public_qt\n",
    "target_col = 'TH'; X = final_data_th[feature_cols]; y = final_data_th[target_col]; score_df = public_th\n",
    "# target_col = 'CK'; X = final_data_ck[feature_cols]; y = final_data_ck[target_col]; score_df = public_ck\n",
    "# target_col = 'TBTL'; X = final_data_tbtl[feature_cols]; y = final_data_tbtl[target_col]; score_df = public_tbtl\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "models = []\n",
    "scalers = []  \n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    scalers.append(scaler)\n",
    "    \n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val_scaled, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    y_pred = model.predict(X_val_scaled, num_iteration=model.best_iteration)\n",
    "    \n",
    "    fold_rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    fold_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold + 1} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "all_data = judgement_lists.merge(score_df, left_on=\"username\", right_on='hash', how='left')\n",
    "test_data = all_data[all_data[target_col].isna()]\n",
    "X_test = test_data[feature_cols]\n",
    "\n",
    "predictions = []\n",
    "for model, scaler in zip(models, scalers):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    pred = model.predict(X_test_scaled, num_iteration=model.best_iteration, predict_disable_shape_check=True)\n",
    "    predictions.append(pred)\n",
    "\n",
    "final_predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "submit_df = pd.DataFrame({'username': test_data['username'], 'score': final_predictions})\n",
    "submit_df.to_csv('submit.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
